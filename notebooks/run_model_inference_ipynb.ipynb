{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24e5233b-a319-45eb-8eae-3236f17546f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install mlflow\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "import cloudpickle\n",
    "import time\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Set the MLflow model registry URI\n",
    "#spark.conf.set(\"spark.mlflow.modelRegistryUri\", \"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_experiment(\"/Users/sagarbansal719@gmail.com/ML_Clf_Model/notebooks/train_model_py.py\") \n",
    "\n",
    "# 1. Model Loader Class\n",
    "class ModelLoader:\n",
    "    def __init__(self, model_name, model_version=None):\n",
    "        \"\"\"\n",
    "        Initializes the ModelLoader class.\n",
    "\n",
    "        :param model_name: Name of the model in MLflow Registry.\n",
    "        :param model_version: (Optional) Specific version to load. Defaults to latest version.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model_version = model_version\n",
    "        self.model = None\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Loads the model from MLflow registry.\"\"\"\n",
    "        model_uri = f\"models:/{self.model_name}/{self.model_version}\" if self.model_version else f\"models:/{self.model_name}@production\"\n",
    "        self.model = mlflow.pyfunc.load_model(model_uri)\n",
    "        print(f\"✅ Model '{self.model_name}' loaded successfully.\")\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"Returns the loaded model instance.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model is not loaded. Call `load_model()` first.\")\n",
    "        return self.model\n",
    "\n",
    "# 2. Data Preprocessing Class\n",
    "class WineDataProcessor:\n",
    "    def __init__(self, feature_columns):\n",
    "        self.data = None\n",
    "        self.feature_columns = feature_columns\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Loads red and white wine datasets and preprocesses them.\"\"\"\n",
    "        data = spark.read.table(\"wine_quality_data.wine_quality_inference_data\").toPandas()\n",
    "        \n",
    "        # Check for missing columns\n",
    "        missing_cols = [col for col in self.feature_columns if col not in data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required features: {missing_cols}\")\n",
    "\n",
    "        self.data = data\n",
    "        return self.data\n",
    "    \n",
    "# 3. Inference Class\n",
    "class WineQualityPredictor:\n",
    "    def __init__(self, model_loader, preprocessor):\n",
    "        \"\"\"\n",
    "        Initializes the predictor with a loaded model and preprocessor.\n",
    "\n",
    "        :param model_loader: Instance of ModelLoader.\n",
    "        :param preprocessor: Instance of DataPreprocessor.\n",
    "        \"\"\"\n",
    "        self.model = model_loader.get_model()\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Runs inference on input data.\"\"\"\n",
    "        processed_data = self.preprocessor.load_data()\n",
    "        predictions = self.model.predict(processed_data)\n",
    "        return predictions\n",
    "\n",
    "#4. Save to Delta Table\n",
    "class DeltaTableSaver:\n",
    "    def __init__(self, catalog, schema, table_name):\n",
    "        \"\"\"\n",
    "        Initializes the DeltaTableSaver class.\n",
    "\n",
    "        :param catalog: The Unity Catalog name.\n",
    "        :param schema: The schema (database) name.\n",
    "        :param table_name: The Delta table name.\n",
    "        \"\"\"\n",
    "        self.catalog = catalog\n",
    "        self.schema = schema\n",
    "        self.table_name = table_name\n",
    "\n",
    "    def save_to_delta(self, df):\n",
    "        \"\"\"Saves the DataFrame as a Delta table in Unity Catalog.\"\"\"\n",
    "        spark_df = spark.createDataFrame(df)\n",
    "\n",
    "        full_table_path = f\"{self.catalog}.{self.schema}.{self.table_name}\"\n",
    "        spark_df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(full_table_path)\n",
    "\n",
    "        print(f\"✅ Predictions saved to Delta table: {full_table_path}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the model name (ensure this matches the registered model in MLflow)\n",
    "    MODEL_NAME = \"wine_quality\"\n",
    "\n",
    "    # Load model\n",
    "    model_loader = ModelLoader(MODEL_NAME)\n",
    "    model_loader.load_model()\n",
    "\n",
    "    # Define feature columns (must match those used during training)\n",
    "    FEATURE_COLUMNS = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
    "       'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol', 'is_red']\n",
    "\n",
    "    # Initialize preprocessor\n",
    "    preprocessor = WineDataProcessor(FEATURE_COLUMNS)\n",
    "\n",
    "    # Initialize predictor\n",
    "    predictor = WineQualityPredictor(model_loader, preprocessor)\n",
    "\n",
    "    # Run inference\n",
    "    predictions = predictor.predict()\n",
    "\n",
    "    # Save results to Delta table in Unity Catalog\n",
    "    spark.createDataFrame(predictions).write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"wine_quality_data.wine_quality_predictions\")\n",
    "\n",
    "    # Print results\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"Sample {i+1} → High Quality Probability: {pred:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "run_model_inference_ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
